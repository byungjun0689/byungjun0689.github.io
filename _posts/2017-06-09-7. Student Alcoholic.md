---
layout: post
title: "Student Alcoholic"
date: 2017-06-09 20:50:26
img: ALCO.PNG
description: 'Student Alcoholic'
main-class: 'Python'
---
# StudentAlcohol
 - 결론 : 당연한 결과가 나온 것 같음.
  - 집과 학교가 거리가 멀고, 친구들과 밖으로 자주 놀러 나가는 남자 아이가 술을 먹을 확률이 높다. 
  - 주중에 먹는애가 주말에 먹고, 주말에 먹는 아이가 주중에 먹을 확률 또한 높다. (당연한 소리)
  - 결석을 자주하는 아이 또한 가능성은 있지만 높은 편은 아니다. 

## Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) datasets: 
 - school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira) 
 - sex - student's sex (binary: 'F' - female or 'M' - male) 
 - age - student's age (numeric: from 15 to 22) 
 - address - student's home address type (binary: 'U' - urban or 'R' - rural) 
 - famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3) 
 - Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart) 
 - Medu - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 Ã¢â‚¬â€œ 5th to 9th grade, 3 Ã¢â‚¬â€œ secondary education or 4 Ã¢â‚¬â€œ higher education) 
 - Fedu - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 Ã¢â‚¬â€œ 5th to 9th grade, 3 Ã¢â‚¬â€œ secondary education or 4 Ã¢â‚¬â€œ higher education) 
 - Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') 
 - Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') 
 - reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other') 
 - guardian - student's guardian (nominal: 'mother', 'father' or 'other') 
 - traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour) 
 - studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours) 
 - failures - number of past class failures (numeric: n if 1<=n<3, else 4) 
 - schoolsup - extra educational support (binary: yes or no) 
 - famsup - family educational support (binary: yes or no) 
 - paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no) 
 - activities - extra-curricular activities (binary: yes or no) 
 - nursery - attended nursery school (binary: yes or no) 
 - higher - wants to take higher education (binary: yes or no) 
 - internet - Internet access at home (binary: yes or no) 
 - romantic - with a romantic relationship (binary: yes or no) 
 - famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent) 
 - freetime - free time after school (numeric: from 1 - very low to 5 - very high) 
 - goout - going out with friends (numeric: from 1 - very low to 5 - very high) 
 - Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high) 
 - Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high) 
 - health - current health status (numeric: from 1 - very bad to 5 - very good) 
 - absences - number of school absences (numeric: from 0 to 93) 

## these grades are related with the course subject, Math or Portuguese: 
 - G1 - first period grade (numeric: from 0 to 20) 
 - G2 - second period grade (numeric: from 0 to 20) 
 - G3 - final grade (numeric: from 0 to 20, output target) 


```python
import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import seaborn as sns 
import datetime as dt 
```


```python
%matplotlib inline
```


```python
df1 = pd.read_csv("data/student-mat.csv") # 수학
df2 = pd.read_csv("data/student-por.csv") # 포르투칼어 
```


```python
df1['class'] = 'math'
df2['class'] = 'por'
```


```python
df = df1.append(df2)
```


```python
df.T.iloc[:,1:5]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>school</th>
      <td>GP</td>
      <td>GP</td>
      <td>GP</td>
      <td>GP</td>
    </tr>
    <tr>
      <th>sex</th>
      <td>F</td>
      <td>F</td>
      <td>F</td>
      <td>F</td>
    </tr>
    <tr>
      <th>age</th>
      <td>17</td>
      <td>15</td>
      <td>15</td>
      <td>16</td>
    </tr>
    <tr>
      <th>address</th>
      <td>U</td>
      <td>U</td>
      <td>U</td>
      <td>U</td>
    </tr>
    <tr>
      <th>famsize</th>
      <td>GT3</td>
      <td>LE3</td>
      <td>GT3</td>
      <td>GT3</td>
    </tr>
    <tr>
      <th>Pstatus</th>
      <td>T</td>
      <td>T</td>
      <td>T</td>
      <td>T</td>
    </tr>
    <tr>
      <th>Medu</th>
      <td>1</td>
      <td>1</td>
      <td>4</td>
      <td>3</td>
    </tr>
    <tr>
      <th>Fedu</th>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>Mjob</th>
      <td>at_home</td>
      <td>at_home</td>
      <td>health</td>
      <td>other</td>
    </tr>
    <tr>
      <th>Fjob</th>
      <td>other</td>
      <td>other</td>
      <td>services</td>
      <td>other</td>
    </tr>
    <tr>
      <th>reason</th>
      <td>course</td>
      <td>other</td>
      <td>home</td>
      <td>home</td>
    </tr>
    <tr>
      <th>guardian</th>
      <td>father</td>
      <td>mother</td>
      <td>mother</td>
      <td>father</td>
    </tr>
    <tr>
      <th>traveltime</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>studytime</th>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>2</td>
    </tr>
    <tr>
      <th>failures</th>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>schoolsup</th>
      <td>no</td>
      <td>yes</td>
      <td>no</td>
      <td>no</td>
    </tr>
    <tr>
      <th>famsup</th>
      <td>yes</td>
      <td>no</td>
      <td>yes</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>paid</th>
      <td>no</td>
      <td>yes</td>
      <td>yes</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>activities</th>
      <td>no</td>
      <td>no</td>
      <td>yes</td>
      <td>no</td>
    </tr>
    <tr>
      <th>nursery</th>
      <td>no</td>
      <td>yes</td>
      <td>yes</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>higher</th>
      <td>yes</td>
      <td>yes</td>
      <td>yes</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>internet</th>
      <td>yes</td>
      <td>yes</td>
      <td>yes</td>
      <td>no</td>
    </tr>
    <tr>
      <th>romantic</th>
      <td>no</td>
      <td>no</td>
      <td>yes</td>
      <td>no</td>
    </tr>
    <tr>
      <th>famrel</th>
      <td>5</td>
      <td>4</td>
      <td>3</td>
      <td>4</td>
    </tr>
    <tr>
      <th>freetime</th>
      <td>3</td>
      <td>3</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>goout</th>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>Dalc</th>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Walc</th>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>health</th>
      <td>3</td>
      <td>3</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>absences</th>
      <td>4</td>
      <td>10</td>
      <td>2</td>
      <td>4</td>
    </tr>
    <tr>
      <th>G1</th>
      <td>5</td>
      <td>7</td>
      <td>15</td>
      <td>6</td>
    </tr>
    <tr>
      <th>G2</th>
      <td>5</td>
      <td>8</td>
      <td>14</td>
      <td>10</td>
    </tr>
    <tr>
      <th>G3</th>
      <td>6</td>
      <td>10</td>
      <td>15</td>
      <td>10</td>
    </tr>
    <tr>
      <th>class</th>
      <td>math</td>
      <td>math</td>
      <td>math</td>
      <td>math</td>
    </tr>
  </tbody>
</table>
</div>



## 탐색적 분석 


```python
print(df['class'].value_counts())
sns.factorplot('class',kind='count', data=df)
```

    por     649
    math    395
    Name: class, dtype: int64
    




    <seaborn.axisgrid.FacetGrid at 0x19b19d91748>




![png](/src/0609/ALCO/output_9_2.png)



```python
print(df['sex'].value_counts())
sns.factorplot('sex',kind='count', data=df)
```

    F    591
    M    453
    Name: sex, dtype: int64
    




    <seaborn.axisgrid.FacetGrid at 0x19b19ddf2e8>




![png](/src/0609/ALCO/output_10_2.png)



```python
print(df['age'].value_counts())
sns.factorplot('age',data=df, kind='count')
```

    16    281
    17    277
    18    222
    15    194
    19     56
    20      9
    21      3
    22      2
    Name: age, dtype: int64
    




    <seaborn.axisgrid.FacetGrid at 0x19b19e4f240>




![png](/src/0609/ALCO/output_11_2.png)



```python
print(df['school'].value_counts())
sns.factorplot('school',kind='count', data=df)
```

    GP    772
    MS    272
    Name: school, dtype: int64
    




    <seaborn.axisgrid.FacetGrid at 0x19b19e81550>




![png](/src/0609/ALCO/output_12_2.png)


 - GridExtra 처럼 그릴 수 있는 방법이 있을텐데... 찾아봐야됨


```python
sns.factorplot('famsize',kind='count', data=df)
sns.factorplot('Pstatus',kind='count', data=df)
sns.factorplot('Medu',kind='count', data=df)
sns.factorplot('Fedu',kind='count', data=df)
sns.factorplot('Mjob',kind='count', data=df)
sns.factorplot('Fjob',kind='count', data=df)
sns.factorplot('reason',kind='count', data=df)
sns.factorplot('guardian',kind='count', data=df)
sns.factorplot('traveltime',kind='count', data=df)
sns.factorplot('studytime',kind='count', data=df)
sns.factorplot('failures',kind='count', data=df)
```




    <seaborn.axisgrid.FacetGrid at 0x19b1b28bba8>




![png](/src/0609/ALCO/output_14_1.png)



![png](/src/0609/ALCO/output_14_2.png)



![png](/src/0609/ALCO/output_14_3.png)



![png](/src/0609/ALCO/output_14_4.png)



![png](/src/0609/ALCO/output_14_5.png)



![png](/src/0609/ALCO/output_14_6.png)



![png](/src/0609/ALCO/output_14_7.png)



![png](/src/0609/ALCO/output_14_8.png)



![png](/src/0609/ALCO/output_14_9.png)



![png](/src/0609/ALCO/output_14_10.png)



![png](/src/0609/ALCO/output_14_11.png)


## Finding Correation with Alcol
 - 연속형 변수와 명목형으로 나누어 명목형은 Dummpy형태로 변환
 - 숫자형이 아닐 경우 Correation을 구할 수가 없다. 


```python
columns = df.columns
discrete = []
continuous = []
for i in columns:
    if df[i].dtype =='object':
        discrete.append(i)
    else:
        continuous.append(i)
```


```python
print(discrete)
```

    ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'class']
    


```python
print(continuous)
```

    ['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']
    


```python
dummy = pd.get_dummies(df[discrete])
```


```python
dummy.head(3)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>school_GP</th>
      <th>school_MS</th>
      <th>sex_F</th>
      <th>sex_M</th>
      <th>address_R</th>
      <th>address_U</th>
      <th>famsize_GT3</th>
      <th>famsize_LE3</th>
      <th>Pstatus_A</th>
      <th>Pstatus_T</th>
      <th>...</th>
      <th>nursery_no</th>
      <th>nursery_yes</th>
      <th>higher_no</th>
      <th>higher_yes</th>
      <th>internet_no</th>
      <th>internet_yes</th>
      <th>romantic_no</th>
      <th>romantic_yes</th>
      <th>class_math</th>
      <th>class_por</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 45 columns</p>
</div>



 - 데이터 결합.


```python
X = pd.concat([df[continuous], dummy], axis=1)
```


```python
X.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>Medu</th>
      <th>Fedu</th>
      <th>traveltime</th>
      <th>studytime</th>
      <th>failures</th>
      <th>famrel</th>
      <th>freetime</th>
      <th>goout</th>
      <th>Dalc</th>
      <th>...</th>
      <th>nursery_no</th>
      <th>nursery_yes</th>
      <th>higher_no</th>
      <th>higher_yes</th>
      <th>internet_no</th>
      <th>internet_yes</th>
      <th>romantic_no</th>
      <th>romantic_yes</th>
      <th>class_math</th>
      <th>class_por</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>18</td>
      <td>4</td>
      <td>4</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>4</td>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>17</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>5</td>
      <td>3</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>15</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
      <td>4</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>15</td>
      <td>4</td>
      <td>2</td>
      <td>1</td>
      <td>3</td>
      <td>0</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>16</td>
      <td>3</td>
      <td>3</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>4</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 61 columns</p>
</div>




```python
corr = X.corr()
```


```python
corr
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>Medu</th>
      <th>Fedu</th>
      <th>traveltime</th>
      <th>studytime</th>
      <th>failures</th>
      <th>famrel</th>
      <th>freetime</th>
      <th>goout</th>
      <th>Dalc</th>
      <th>...</th>
      <th>nursery_no</th>
      <th>nursery_yes</th>
      <th>higher_no</th>
      <th>higher_yes</th>
      <th>internet_no</th>
      <th>internet_yes</th>
      <th>romantic_no</th>
      <th>romantic_yes</th>
      <th>class_math</th>
      <th>class_por</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>age</th>
      <td>1.000000</td>
      <td>-0.130196</td>
      <td>-0.138521</td>
      <td>0.049216</td>
      <td>-0.007870</td>
      <td>0.282364</td>
      <td>0.007162</td>
      <td>0.002645</td>
      <td>0.118510</td>
      <td>0.133453</td>
      <td>...</td>
      <td>0.046846</td>
      <td>-0.046846</td>
      <td>0.244601</td>
      <td>-0.244601</td>
      <td>0.033229</td>
      <td>-0.033229</td>
      <td>-0.173800</td>
      <td>0.173800</td>
      <td>-0.018790</td>
      <td>0.018790</td>
    </tr>
    <tr>
      <th>Medu</th>
      <td>-0.130196</td>
      <td>1.000000</td>
      <td>0.642063</td>
      <td>-0.238181</td>
      <td>0.090616</td>
      <td>-0.187769</td>
      <td>0.015004</td>
      <td>0.001054</td>
      <td>0.025614</td>
      <td>0.001515</td>
      <td>...</td>
      <td>-0.149287</td>
      <td>0.149287</td>
      <td>-0.206551</td>
      <td>0.206551</td>
      <td>-0.249728</td>
      <td>0.249728</td>
      <td>0.008685</td>
      <td>-0.008685</td>
      <td>0.101246</td>
      <td>-0.101246</td>
    </tr>
    <tr>
      <th>Fedu</th>
      <td>-0.138521</td>
      <td>0.642063</td>
      <td>1.000000</td>
      <td>-0.196328</td>
      <td>0.033458</td>
      <td>-0.191390</td>
      <td>0.013066</td>
      <td>0.002142</td>
      <td>0.030075</td>
      <td>-0.000165</td>
      <td>...</td>
      <td>-0.104681</td>
      <td>0.104681</td>
      <td>-0.191956</td>
      <td>0.191956</td>
      <td>-0.170012</td>
      <td>0.170012</td>
      <td>0.039906</td>
      <td>-0.039906</td>
      <td>0.094795</td>
      <td>-0.094795</td>
    </tr>
    <tr>
      <th>traveltime</th>
      <td>0.049216</td>
      <td>-0.238181</td>
      <td>-0.196328</td>
      <td>1.000000</td>
      <td>-0.081328</td>
      <td>0.087177</td>
      <td>-0.012578</td>
      <td>-0.007403</td>
      <td>0.049740</td>
      <td>0.109423</td>
      <td>...</td>
      <td>0.018641</td>
      <td>-0.018641</td>
      <td>0.081857</td>
      <td>-0.081857</td>
      <td>0.169485</td>
      <td>-0.169485</td>
      <td>-0.013603</td>
      <td>0.013603</td>
      <td>-0.079881</td>
      <td>0.079881</td>
    </tr>
    <tr>
      <th>studytime</th>
      <td>-0.007870</td>
      <td>0.090616</td>
      <td>0.033458</td>
      <td>-0.081328</td>
      <td>1.000000</td>
      <td>-0.152024</td>
      <td>0.012324</td>
      <td>-0.094429</td>
      <td>-0.072941</td>
      <td>-0.159665</td>
      <td>...</td>
      <td>-0.056817</td>
      <td>0.056817</td>
      <td>-0.186556</td>
      <td>0.186556</td>
      <td>-0.049695</td>
      <td>0.049695</td>
      <td>-0.038435</td>
      <td>0.038435</td>
      <td>0.060934</td>
      <td>-0.060934</td>
    </tr>
    <tr>
      <th>failures</th>
      <td>0.282364</td>
      <td>-0.187769</td>
      <td>-0.191390</td>
      <td>0.087177</td>
      <td>-0.152024</td>
      <td>1.000000</td>
      <td>-0.053676</td>
      <td>0.102679</td>
      <td>0.074683</td>
      <td>0.116336</td>
      <td>...</td>
      <td>0.083027</td>
      <td>-0.083027</td>
      <td>0.284893</td>
      <td>-0.284893</td>
      <td>0.074263</td>
      <td>-0.074263</td>
      <td>-0.076042</td>
      <td>0.076042</td>
      <td>0.083043</td>
      <td>-0.083043</td>
    </tr>
    <tr>
      <th>famrel</th>
      <td>0.007162</td>
      <td>0.015004</td>
      <td>0.013066</td>
      <td>-0.012578</td>
      <td>0.012324</td>
      <td>-0.053676</td>
      <td>1.000000</td>
      <td>0.136901</td>
      <td>0.080619</td>
      <td>-0.076483</td>
      <td>...</td>
      <td>-0.024599</td>
      <td>0.024599</td>
      <td>-0.041502</td>
      <td>0.041502</td>
      <td>-0.065972</td>
      <td>0.065972</td>
      <td>0.051891</td>
      <td>-0.051891</td>
      <td>0.007091</td>
      <td>-0.007091</td>
    </tr>
    <tr>
      <th>freetime</th>
      <td>0.002645</td>
      <td>0.001054</td>
      <td>0.002142</td>
      <td>-0.007403</td>
      <td>-0.094429</td>
      <td>0.102679</td>
      <td>0.136901</td>
      <td>1.000000</td>
      <td>0.323556</td>
      <td>0.144979</td>
      <td>...</td>
      <td>0.013837</td>
      <td>-0.013837</td>
      <td>0.086824</td>
      <td>-0.086824</td>
      <td>-0.061016</td>
      <td>0.061016</td>
      <td>-0.012372</td>
      <td>0.012372</td>
      <td>0.025949</td>
      <td>-0.025949</td>
    </tr>
    <tr>
      <th>goout</th>
      <td>0.118510</td>
      <td>0.025614</td>
      <td>0.030075</td>
      <td>0.049740</td>
      <td>-0.072941</td>
      <td>0.074683</td>
      <td>0.080619</td>
      <td>0.323556</td>
      <td>1.000000</td>
      <td>0.253135</td>
      <td>...</td>
      <td>-0.013779</td>
      <td>0.013779</td>
      <td>0.062837</td>
      <td>-0.062837</td>
      <td>-0.083766</td>
      <td>0.083766</td>
      <td>-0.003606</td>
      <td>0.003606</td>
      <td>-0.032011</td>
      <td>0.032011</td>
    </tr>
    <tr>
      <th>Dalc</th>
      <td>0.133453</td>
      <td>0.001515</td>
      <td>-0.000165</td>
      <td>0.109423</td>
      <td>-0.159665</td>
      <td>0.116336</td>
      <td>-0.076483</td>
      <td>0.144979</td>
      <td>0.253135</td>
      <td>1.000000</td>
      <td>...</td>
      <td>0.080647</td>
      <td>-0.080647</td>
      <td>0.112964</td>
      <td>-0.112964</td>
      <td>-0.039511</td>
      <td>0.039511</td>
      <td>-0.045311</td>
      <td>0.045311</td>
      <td>-0.011335</td>
      <td>0.011335</td>
    </tr>
    <tr>
      <th>Walc</th>
      <td>0.098291</td>
      <td>-0.029331</td>
      <td>0.019524</td>
      <td>0.084292</td>
      <td>-0.229073</td>
      <td>0.107432</td>
      <td>-0.100663</td>
      <td>0.130377</td>
      <td>0.399794</td>
      <td>0.627814</td>
      <td>...</td>
      <td>0.084874</td>
      <td>-0.084874</td>
      <td>0.087271</td>
      <td>-0.087271</td>
      <td>-0.043615</td>
      <td>0.043615</td>
      <td>0.016426</td>
      <td>-0.016426</td>
      <td>0.004043</td>
      <td>-0.004043</td>
    </tr>
    <tr>
      <th>health</th>
      <td>-0.029129</td>
      <td>-0.013254</td>
      <td>0.034288</td>
      <td>-0.029002</td>
      <td>-0.063044</td>
      <td>0.048311</td>
      <td>0.104101</td>
      <td>0.081517</td>
      <td>-0.013736</td>
      <td>0.065515</td>
      <td>...</td>
      <td>0.005869</td>
      <td>-0.005869</td>
      <td>-0.008036</td>
      <td>0.008036</td>
      <td>0.041685</td>
      <td>-0.041685</td>
      <td>0.002096</td>
      <td>-0.002096</td>
      <td>0.006205</td>
      <td>-0.006205</td>
    </tr>
    <tr>
      <th>absences</th>
      <td>0.153196</td>
      <td>0.059708</td>
      <td>0.040829</td>
      <td>-0.022669</td>
      <td>-0.075594</td>
      <td>0.099998</td>
      <td>-0.062171</td>
      <td>-0.032079</td>
      <td>0.056142</td>
      <td>0.132867</td>
      <td>...</td>
      <td>0.010842</td>
      <td>-0.010842</td>
      <td>0.072556</td>
      <td>-0.072556</td>
      <td>-0.090652</td>
      <td>0.090652</td>
      <td>-0.105323</td>
      <td>0.105323</td>
      <td>0.160125</td>
      <td>-0.160125</td>
    </tr>
    <tr>
      <th>G1</th>
      <td>-0.124121</td>
      <td>0.226101</td>
      <td>0.195898</td>
      <td>-0.121053</td>
      <td>0.211314</td>
      <td>-0.374175</td>
      <td>0.036947</td>
      <td>-0.051985</td>
      <td>-0.101163</td>
      <td>-0.150943</td>
      <td>...</td>
      <td>-0.047878</td>
      <td>0.047878</td>
      <td>-0.271476</td>
      <td>0.271476</td>
      <td>-0.104772</td>
      <td>0.104772</td>
      <td>0.055869</td>
      <td>-0.055869</td>
      <td>-0.079727</td>
      <td>0.079727</td>
    </tr>
    <tr>
      <th>G2</th>
      <td>-0.119475</td>
      <td>0.224662</td>
      <td>0.182634</td>
      <td>-0.140163</td>
      <td>0.183167</td>
      <td>-0.377172</td>
      <td>0.042054</td>
      <td>-0.068952</td>
      <td>-0.108411</td>
      <td>-0.131576</td>
      <td>...</td>
      <td>-0.052818</td>
      <td>0.052818</td>
      <td>-0.250619</td>
      <td>0.250619</td>
      <td>-0.122517</td>
      <td>0.122517</td>
      <td>0.097719</td>
      <td>-0.097719</td>
      <td>-0.126459</td>
      <td>0.126459</td>
    </tr>
    <tr>
      <th>G3</th>
      <td>-0.125282</td>
      <td>0.201472</td>
      <td>0.159796</td>
      <td>-0.102627</td>
      <td>0.161629</td>
      <td>-0.383145</td>
      <td>0.054461</td>
      <td>-0.064890</td>
      <td>-0.097877</td>
      <td>-0.129642</td>
      <td>...</td>
      <td>-0.039950</td>
      <td>0.039950</td>
      <td>-0.236578</td>
      <td>0.236578</td>
      <td>-0.107064</td>
      <td>0.107064</td>
      <td>0.098363</td>
      <td>-0.098363</td>
      <td>-0.187166</td>
      <td>0.187166</td>
    </tr>
    <tr>
      <th>school_GP</th>
      <td>-0.169938</td>
      <td>0.235114</td>
      <td>0.187611</td>
      <td>-0.258834</td>
      <td>0.133255</td>
      <td>-0.066856</td>
      <td>0.036359</td>
      <td>-0.026008</td>
      <td>-0.037000</td>
      <td>-0.066006</td>
      <td>...</td>
      <td>-0.019349</td>
      <td>0.019349</td>
      <td>-0.131382</td>
      <td>0.131382</td>
      <td>-0.222993</td>
      <td>0.222993</td>
      <td>0.074506</td>
      <td>-0.074506</td>
      <td>0.256088</td>
      <td>-0.256088</td>
    </tr>
    <tr>
      <th>school_MS</th>
      <td>0.169938</td>
      <td>-0.235114</td>
      <td>-0.187611</td>
      <td>0.258834</td>
      <td>-0.133255</td>
      <td>0.066856</td>
      <td>-0.036359</td>
      <td>0.026008</td>
      <td>0.037000</td>
      <td>0.066006</td>
      <td>...</td>
      <td>0.019349</td>
      <td>-0.019349</td>
      <td>0.131382</td>
      <td>-0.131382</td>
      <td>0.222993</td>
      <td>-0.222993</td>
      <td>-0.074506</td>
      <td>0.074506</td>
      <td>-0.256088</td>
      <td>0.256088</td>
    </tr>
    <tr>
      <th>sex_F</th>
      <td>0.038832</td>
      <td>-0.109387</td>
      <td>-0.070786</td>
      <td>-0.042508</td>
      <td>0.239972</td>
      <td>-0.065543</td>
      <td>-0.074725</td>
      <td>-0.181603</td>
      <td>-0.062530</td>
      <td>-0.275928</td>
      <td>...</td>
      <td>-0.030492</td>
      <td>0.030492</td>
      <td>-0.078775</td>
      <td>0.078775</td>
      <td>0.062671</td>
      <td>-0.062671</td>
      <td>-0.108944</td>
      <td>0.108944</td>
      <td>-0.062192</td>
      <td>0.062192</td>
    </tr>
    <tr>
      <th>sex_M</th>
      <td>-0.038832</td>
      <td>0.109387</td>
      <td>0.070786</td>
      <td>0.042508</td>
      <td>-0.239972</td>
      <td>0.065543</td>
      <td>0.074725</td>
      <td>0.181603</td>
      <td>0.062530</td>
      <td>0.275928</td>
      <td>...</td>
      <td>0.030492</td>
      <td>-0.030492</td>
      <td>0.078775</td>
      <td>-0.078775</td>
      <td>-0.062671</td>
      <td>0.062671</td>
      <td>0.108944</td>
      <td>-0.108944</td>
      <td>0.062192</td>
      <td>-0.062192</td>
    </tr>
    <tr>
      <th>address_R</th>
      <td>0.071257</td>
      <td>-0.179720</td>
      <td>-0.124303</td>
      <td>0.343803</td>
      <td>-0.037480</td>
      <td>0.061160</td>
      <td>0.016801</td>
      <td>0.009744</td>
      <td>-0.030790</td>
      <td>0.064030</td>
      <td>...</td>
      <td>0.031946</td>
      <td>-0.031946</td>
      <td>0.074716</td>
      <td>-0.074716</td>
      <td>0.194790</td>
      <td>-0.194790</td>
      <td>-0.021209</td>
      <td>0.021209</td>
      <td>-0.087916</td>
      <td>0.087916</td>
    </tr>
    <tr>
      <th>address_U</th>
      <td>-0.071257</td>
      <td>0.179720</td>
      <td>0.124303</td>
      <td>-0.343803</td>
      <td>0.037480</td>
      <td>-0.061160</td>
      <td>-0.016801</td>
      <td>-0.009744</td>
      <td>0.030790</td>
      <td>-0.064030</td>
      <td>...</td>
      <td>-0.031946</td>
      <td>0.031946</td>
      <td>-0.074716</td>
      <td>0.074716</td>
      <td>-0.194790</td>
      <td>0.194790</td>
      <td>0.021209</td>
      <td>-0.021209</td>
      <td>0.087916</td>
      <td>-0.087916</td>
    </tr>
    <tr>
      <th>famsize_GT3</th>
      <td>-0.013290</td>
      <td>0.025556</td>
      <td>0.047290</td>
      <td>-0.031550</td>
      <td>0.035109</td>
      <td>0.044589</td>
      <td>0.005328</td>
      <td>0.007249</td>
      <td>-0.005889</td>
      <td>-0.075646</td>
      <td>...</td>
      <td>0.101279</td>
      <td>-0.101279</td>
      <td>0.000650</td>
      <td>-0.000650</td>
      <td>0.008315</td>
      <td>-0.008315</td>
      <td>-0.007656</td>
      <td>0.007656</td>
      <td>0.007705</td>
      <td>-0.007705</td>
    </tr>
    <tr>
      <th>famsize_LE3</th>
      <td>0.013290</td>
      <td>-0.025556</td>
      <td>-0.047290</td>
      <td>0.031550</td>
      <td>-0.035109</td>
      <td>-0.044589</td>
      <td>-0.005328</td>
      <td>-0.007249</td>
      <td>0.005889</td>
      <td>0.075646</td>
      <td>...</td>
      <td>-0.101279</td>
      <td>0.101279</td>
      <td>-0.000650</td>
      <td>0.000650</td>
      <td>-0.008315</td>
      <td>0.008315</td>
      <td>0.007656</td>
      <td>-0.007656</td>
      <td>-0.007705</td>
      <td>0.007705</td>
    </tr>
    <tr>
      <th>Pstatus_A</th>
      <td>-0.006887</td>
      <td>0.077133</td>
      <td>0.049156</td>
      <td>-0.033883</td>
      <td>-0.005049</td>
      <td>0.004615</td>
      <td>-0.042448</td>
      <td>-0.038714</td>
      <td>-0.020498</td>
      <td>-0.015777</td>
      <td>...</td>
      <td>-0.054016</td>
      <td>0.054016</td>
      <td>0.007339</td>
      <td>-0.007339</td>
      <td>0.065260</td>
      <td>-0.065260</td>
      <td>-0.050021</td>
      <td>0.050021</td>
      <td>-0.029497</td>
      <td>0.029497</td>
    </tr>
    <tr>
      <th>Pstatus_T</th>
      <td>0.006887</td>
      <td>-0.077133</td>
      <td>-0.049156</td>
      <td>0.033883</td>
      <td>0.005049</td>
      <td>-0.004615</td>
      <td>0.042448</td>
      <td>0.038714</td>
      <td>0.020498</td>
      <td>0.015777</td>
      <td>...</td>
      <td>0.054016</td>
      <td>-0.054016</td>
      <td>-0.007339</td>
      <td>0.007339</td>
      <td>-0.065260</td>
      <td>0.065260</td>
      <td>0.050021</td>
      <td>-0.050021</td>
      <td>0.029497</td>
      <td>-0.029497</td>
    </tr>
    <tr>
      <th>Mjob_at_home</th>
      <td>0.089702</td>
      <td>-0.387814</td>
      <td>-0.188731</td>
      <td>0.170171</td>
      <td>-0.018424</td>
      <td>0.070264</td>
      <td>-0.017289</td>
      <td>-0.047825</td>
      <td>-0.036958</td>
      <td>-0.015903</td>
      <td>...</td>
      <td>0.025619</td>
      <td>-0.025619</td>
      <td>0.153985</td>
      <td>-0.153985</td>
      <td>0.240790</td>
      <td>-0.240790</td>
      <td>-0.036321</td>
      <td>0.036321</td>
      <td>-0.073121</td>
      <td>0.073121</td>
    </tr>
    <tr>
      <th>Mjob_health</th>
      <td>-0.093470</td>
      <td>0.258135</td>
      <td>0.133393</td>
      <td>-0.106540</td>
      <td>-0.015221</td>
      <td>-0.025398</td>
      <td>-0.040978</td>
      <td>-0.015520</td>
      <td>0.046969</td>
      <td>-0.076301</td>
      <td>...</td>
      <td>-0.048189</td>
      <td>0.048189</td>
      <td>-0.089128</td>
      <td>0.089128</td>
      <td>-0.088132</td>
      <td>0.088132</td>
      <td>-0.021277</td>
      <td>0.021277</td>
      <td>0.021842</td>
      <td>-0.021842</td>
    </tr>
    <tr>
      <th>Mjob_other</th>
      <td>0.037066</td>
      <td>-0.231026</td>
      <td>-0.200426</td>
      <td>0.038616</td>
      <td>-0.007451</td>
      <td>-0.001451</td>
      <td>0.003394</td>
      <td>-0.017702</td>
      <td>0.006338</td>
      <td>-0.004774</td>
      <td>...</td>
      <td>0.089281</td>
      <td>-0.089281</td>
      <td>0.021075</td>
      <td>-0.021075</td>
      <td>0.063474</td>
      <td>-0.063474</td>
      <td>-0.042049</td>
      <td>0.042049</td>
      <td>-0.040494</td>
      <td>0.040494</td>
    </tr>
    <tr>
      <th>Mjob_services</th>
      <td>-0.024883</td>
      <td>0.104984</td>
      <td>0.079390</td>
      <td>-0.068560</td>
      <td>0.019401</td>
      <td>0.058457</td>
      <td>0.044812</td>
      <td>0.017525</td>
      <td>0.031040</td>
      <td>0.044716</td>
      <td>...</td>
      <td>-0.027609</td>
      <td>0.027609</td>
      <td>-0.035714</td>
      <td>0.035714</td>
      <td>-0.127412</td>
      <td>0.127412</td>
      <td>0.056836</td>
      <td>-0.056836</td>
      <td>0.059108</td>
      <td>-0.059108</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>Fjob_at_home</th>
      <td>0.065349</td>
      <td>-0.091603</td>
      <td>-0.084975</td>
      <td>-0.052228</td>
      <td>0.004087</td>
      <td>0.028483</td>
      <td>-0.069595</td>
      <td>0.045318</td>
      <td>-0.023500</td>
      <td>-0.029547</td>
      <td>...</td>
      <td>-0.054813</td>
      <td>0.054813</td>
      <td>0.068422</td>
      <td>-0.068422</td>
      <td>0.071043</td>
      <td>-0.071043</td>
      <td>-0.033594</td>
      <td>0.033594</td>
      <td>-0.028896</td>
      <td>0.028896</td>
    </tr>
    <tr>
      <th>Fjob_health</th>
      <td>-0.106505</td>
      <td>0.128323</td>
      <td>0.202267</td>
      <td>-0.090635</td>
      <td>0.107722</td>
      <td>-0.036386</td>
      <td>0.003336</td>
      <td>-0.039445</td>
      <td>0.006843</td>
      <td>-0.017665</td>
      <td>...</td>
      <td>-0.051856</td>
      <td>0.051856</td>
      <td>-0.044062</td>
      <td>0.044062</td>
      <td>0.005809</td>
      <td>-0.005809</td>
      <td>0.016175</td>
      <td>-0.016175</td>
      <td>0.025293</td>
      <td>-0.025293</td>
    </tr>
    <tr>
      <th>Fjob_other</th>
      <td>0.038894</td>
      <td>-0.115679</td>
      <td>-0.230861</td>
      <td>0.099122</td>
      <td>-0.038541</td>
      <td>0.007676</td>
      <td>0.017535</td>
      <td>0.038416</td>
      <td>0.043242</td>
      <td>-0.060645</td>
      <td>...</td>
      <td>0.043820</td>
      <td>-0.043820</td>
      <td>0.001482</td>
      <td>-0.001482</td>
      <td>0.021934</td>
      <td>-0.021934</td>
      <td>0.018271</td>
      <td>-0.018271</td>
      <td>-0.015745</td>
      <td>0.015745</td>
    </tr>
    <tr>
      <th>Fjob_services</th>
      <td>0.001709</td>
      <td>-0.019372</td>
      <td>0.024698</td>
      <td>-0.031258</td>
      <td>0.011951</td>
      <td>0.031904</td>
      <td>0.045152</td>
      <td>-0.051199</td>
      <td>-0.021470</td>
      <td>0.097602</td>
      <td>...</td>
      <td>0.008235</td>
      <td>-0.008235</td>
      <td>0.008462</td>
      <td>-0.008462</td>
      <td>-0.066757</td>
      <td>0.066757</td>
      <td>0.003417</td>
      <td>-0.003417</td>
      <td>0.002293</td>
      <td>-0.002293</td>
    </tr>
    <tr>
      <th>Fjob_teacher</th>
      <td>-0.061390</td>
      <td>0.260111</td>
      <td>0.348978</td>
      <td>-0.021649</td>
      <td>-0.033607</td>
      <td>-0.073646</td>
      <td>-0.054509</td>
      <td>0.003558</td>
      <td>-0.031480</td>
      <td>-0.013600</td>
      <td>...</td>
      <td>-0.010030</td>
      <td>0.010030</td>
      <td>-0.050270</td>
      <td>0.050270</td>
      <td>0.004782</td>
      <td>-0.004782</td>
      <td>-0.024030</td>
      <td>0.024030</td>
      <td>0.036023</td>
      <td>-0.036023</td>
    </tr>
    <tr>
      <th>reason_course</th>
      <td>0.018524</td>
      <td>-0.116806</td>
      <td>-0.059851</td>
      <td>0.128033</td>
      <td>-0.084553</td>
      <td>0.098883</td>
      <td>-0.005015</td>
      <td>0.082123</td>
      <td>0.028489</td>
      <td>-0.033164</td>
      <td>...</td>
      <td>0.033645</td>
      <td>-0.033645</td>
      <td>0.086021</td>
      <td>-0.086021</td>
      <td>0.103707</td>
      <td>-0.103707</td>
      <td>-0.004853</td>
      <td>0.004853</td>
      <td>-0.070995</td>
      <td>0.070995</td>
    </tr>
    <tr>
      <th>reason_home</th>
      <td>-0.002368</td>
      <td>0.024313</td>
      <td>0.011945</td>
      <td>-0.112132</td>
      <td>-0.019542</td>
      <td>-0.021017</td>
      <td>-0.017715</td>
      <td>-0.064393</td>
      <td>-0.012108</td>
      <td>0.045040</td>
      <td>...</td>
      <td>0.007495</td>
      <td>-0.007495</td>
      <td>-0.055619</td>
      <td>0.055619</td>
      <td>-0.063627</td>
      <td>0.063627</td>
      <td>-0.010746</td>
      <td>0.010746</td>
      <td>0.052131</td>
      <td>-0.052131</td>
    </tr>
    <tr>
      <th>reason_other</th>
      <td>0.006563</td>
      <td>-0.022861</td>
      <td>-0.025451</td>
      <td>0.040928</td>
      <td>-0.097277</td>
      <td>-0.007442</td>
      <td>0.003139</td>
      <td>-0.008310</td>
      <td>-0.002354</td>
      <td>0.133297</td>
      <td>...</td>
      <td>0.002981</td>
      <td>-0.002981</td>
      <td>0.076511</td>
      <td>-0.076511</td>
      <td>0.043032</td>
      <td>-0.043032</td>
      <td>-0.050078</td>
      <td>0.050078</td>
      <td>-0.031532</td>
      <td>0.031532</td>
    </tr>
    <tr>
      <th>reason_reputation</th>
      <td>-0.023719</td>
      <td>0.126800</td>
      <td>0.075322</td>
      <td>-0.063705</td>
      <td>0.187202</td>
      <td>-0.087729</td>
      <td>0.021509</td>
      <td>-0.023762</td>
      <td>-0.018991</td>
      <td>-0.102682</td>
      <td>...</td>
      <td>-0.048640</td>
      <td>0.048640</td>
      <td>-0.097860</td>
      <td>0.097860</td>
      <td>-0.086240</td>
      <td>0.086240</td>
      <td>0.052339</td>
      <td>-0.052339</td>
      <td>0.051832</td>
      <td>-0.051832</td>
    </tr>
    <tr>
      <th>guardian_father</th>
      <td>-0.126978</td>
      <td>-0.043620</td>
      <td>0.094286</td>
      <td>0.024526</td>
      <td>0.011457</td>
      <td>-0.059589</td>
      <td>0.008734</td>
      <td>-0.032711</td>
      <td>-0.064810</td>
      <td>0.034565</td>
      <td>...</td>
      <td>0.018996</td>
      <td>-0.018996</td>
      <td>-0.022041</td>
      <td>0.022041</td>
      <td>-0.025185</td>
      <td>0.025185</td>
      <td>0.049031</td>
      <td>-0.049031</td>
      <td>-0.009065</td>
      <td>0.009065</td>
    </tr>
    <tr>
      <th>guardian_mother</th>
      <td>-0.081701</td>
      <td>0.097703</td>
      <td>-0.046298</td>
      <td>-0.061961</td>
      <td>-0.020958</td>
      <td>-0.090476</td>
      <td>0.003844</td>
      <td>0.003161</td>
      <td>0.056714</td>
      <td>-0.077368</td>
      <td>...</td>
      <td>-0.087220</td>
      <td>0.087220</td>
      <td>-0.052720</td>
      <td>0.052720</td>
      <td>0.024057</td>
      <td>-0.024057</td>
      <td>0.024851</td>
      <td>-0.024851</td>
      <td>-0.010492</td>
      <td>0.010492</td>
    </tr>
    <tr>
      <th>guardian_other</th>
      <td>0.357601</td>
      <td>-0.103730</td>
      <td>-0.072834</td>
      <td>0.070983</td>
      <td>0.018770</td>
      <td>0.261738</td>
      <td>-0.021398</td>
      <td>0.048511</td>
      <td>0.005225</td>
      <td>0.082103</td>
      <td>...</td>
      <td>0.125651</td>
      <td>-0.125651</td>
      <td>0.131501</td>
      <td>-0.131501</td>
      <td>-0.001605</td>
      <td>0.001605</td>
      <td>-0.126020</td>
      <td>0.126020</td>
      <td>0.033924</td>
      <td>-0.033924</td>
    </tr>
    <tr>
      <th>schoolsup_no</th>
      <td>0.202824</td>
      <td>0.023618</td>
      <td>-0.032450</td>
      <td>0.033940</td>
      <td>-0.070598</td>
      <td>-0.002483</td>
      <td>0.007634</td>
      <td>0.026126</td>
      <td>0.051227</td>
      <td>0.025852</td>
      <td>...</td>
      <td>0.028795</td>
      <td>-0.028795</td>
      <td>0.077115</td>
      <td>-0.077115</td>
      <td>-0.016827</td>
      <td>0.016827</td>
      <td>-0.089979</td>
      <td>0.089979</td>
      <td>-0.037141</td>
      <td>0.037141</td>
    </tr>
    <tr>
      <th>schoolsup_yes</th>
      <td>-0.202824</td>
      <td>-0.023618</td>
      <td>0.032450</td>
      <td>-0.033940</td>
      <td>0.070598</td>
      <td>0.002483</td>
      <td>-0.007634</td>
      <td>-0.026126</td>
      <td>-0.051227</td>
      <td>-0.025852</td>
      <td>...</td>
      <td>-0.028795</td>
      <td>0.028795</td>
      <td>-0.077115</td>
      <td>0.077115</td>
      <td>0.016827</td>
      <td>-0.016827</td>
      <td>0.089979</td>
      <td>-0.089979</td>
      <td>0.037141</td>
      <td>-0.037141</td>
    </tr>
    <tr>
      <th>famsup_no</th>
      <td>0.116904</td>
      <td>-0.143063</td>
      <td>-0.153342</td>
      <td>0.026117</td>
      <td>-0.143858</td>
      <td>0.027574</td>
      <td>-0.002261</td>
      <td>-0.006227</td>
      <td>-0.005252</td>
      <td>0.022275</td>
      <td>...</td>
      <td>0.039921</td>
      <td>-0.039921</td>
      <td>0.088449</td>
      <td>-0.088449</td>
      <td>0.082522</td>
      <td>-0.082522</td>
      <td>-0.009997</td>
      <td>0.009997</td>
      <td>0.000590</td>
      <td>-0.000590</td>
    </tr>
    <tr>
      <th>famsup_yes</th>
      <td>-0.116904</td>
      <td>0.143063</td>
      <td>0.153342</td>
      <td>-0.026117</td>
      <td>0.143858</td>
      <td>-0.027574</td>
      <td>0.002261</td>
      <td>0.006227</td>
      <td>0.005252</td>
      <td>-0.022275</td>
      <td>...</td>
      <td>-0.039921</td>
      <td>0.039921</td>
      <td>-0.088449</td>
      <td>0.088449</td>
      <td>-0.082522</td>
      <td>0.082522</td>
      <td>0.009997</td>
      <td>-0.009997</td>
      <td>-0.000590</td>
      <td>0.000590</td>
    </tr>
    <tr>
      <th>paid_no</th>
      <td>0.027917</td>
      <td>-0.161349</td>
      <td>-0.118897</td>
      <td>0.083679</td>
      <td>-0.105704</td>
      <td>0.036389</td>
      <td>-0.015404</td>
      <td>0.034747</td>
      <td>0.012943</td>
      <td>-0.041919</td>
      <td>...</td>
      <td>0.053074</td>
      <td>-0.053074</td>
      <td>0.124097</td>
      <td>-0.124097</td>
      <td>0.114189</td>
      <td>-0.114189</td>
      <td>-0.020512</td>
      <td>0.020512</td>
      <td>-0.473453</td>
      <td>0.473453</td>
    </tr>
    <tr>
      <th>paid_yes</th>
      <td>-0.027917</td>
      <td>0.161349</td>
      <td>0.118897</td>
      <td>-0.083679</td>
      <td>0.105704</td>
      <td>-0.036389</td>
      <td>0.015404</td>
      <td>-0.034747</td>
      <td>-0.012943</td>
      <td>0.041919</td>
      <td>...</td>
      <td>-0.053074</td>
      <td>0.053074</td>
      <td>-0.124097</td>
      <td>0.124097</td>
      <td>-0.114189</td>
      <td>0.114189</td>
      <td>0.020512</td>
      <td>-0.020512</td>
      <td>0.473453</td>
      <td>-0.473453</td>
    </tr>
    <tr>
      <th>activities_no</th>
      <td>0.073648</td>
      <td>-0.116924</td>
      <td>-0.093800</td>
      <td>0.025834</td>
      <td>-0.078847</td>
      <td>0.027500</td>
      <td>-0.051574</td>
      <td>-0.128601</td>
      <td>-0.072236</td>
      <td>0.010584</td>
      <td>...</td>
      <td>0.025370</td>
      <td>-0.025370</td>
      <td>0.061667</td>
      <td>-0.061667</td>
      <td>0.072016</td>
      <td>-0.072016</td>
      <td>0.042559</td>
      <td>-0.042559</td>
      <td>-0.022794</td>
      <td>0.022794</td>
    </tr>
    <tr>
      <th>activities_yes</th>
      <td>-0.073648</td>
      <td>0.116924</td>
      <td>0.093800</td>
      <td>-0.025834</td>
      <td>0.078847</td>
      <td>-0.027500</td>
      <td>0.051574</td>
      <td>0.128601</td>
      <td>0.072236</td>
      <td>-0.010584</td>
      <td>...</td>
      <td>-0.025370</td>
      <td>0.025370</td>
      <td>-0.061667</td>
      <td>0.061667</td>
      <td>-0.072016</td>
      <td>0.072016</td>
      <td>-0.042559</td>
      <td>0.042559</td>
      <td>0.022794</td>
      <td>-0.022794</td>
    </tr>
    <tr>
      <th>nursery_no</th>
      <td>0.046846</td>
      <td>-0.149287</td>
      <td>-0.104681</td>
      <td>0.018641</td>
      <td>-0.056817</td>
      <td>0.083027</td>
      <td>-0.024599</td>
      <td>0.013837</td>
      <td>-0.013779</td>
      <td>0.080647</td>
      <td>...</td>
      <td>1.000000</td>
      <td>-1.000000</td>
      <td>0.044429</td>
      <td>-0.044429</td>
      <td>-0.002605</td>
      <td>0.002605</td>
      <td>-0.003646</td>
      <td>0.003646</td>
      <td>0.009498</td>
      <td>-0.009498</td>
    </tr>
    <tr>
      <th>nursery_yes</th>
      <td>-0.046846</td>
      <td>0.149287</td>
      <td>0.104681</td>
      <td>-0.018641</td>
      <td>0.056817</td>
      <td>-0.083027</td>
      <td>0.024599</td>
      <td>-0.013837</td>
      <td>0.013779</td>
      <td>-0.080647</td>
      <td>...</td>
      <td>-1.000000</td>
      <td>1.000000</td>
      <td>-0.044429</td>
      <td>0.044429</td>
      <td>0.002605</td>
      <td>-0.002605</td>
      <td>0.003646</td>
      <td>-0.003646</td>
      <td>-0.009498</td>
      <td>0.009498</td>
    </tr>
    <tr>
      <th>higher_no</th>
      <td>0.244601</td>
      <td>-0.206551</td>
      <td>-0.191956</td>
      <td>0.081857</td>
      <td>-0.186556</td>
      <td>0.284893</td>
      <td>-0.041502</td>
      <td>0.086824</td>
      <td>0.062837</td>
      <td>0.112964</td>
      <td>...</td>
      <td>0.044429</td>
      <td>-0.044429</td>
      <td>1.000000</td>
      <td>-1.000000</td>
      <td>0.063407</td>
      <td>-0.063407</td>
      <td>-0.103002</td>
      <td>0.103002</td>
      <td>-0.096707</td>
      <td>0.096707</td>
    </tr>
    <tr>
      <th>higher_yes</th>
      <td>-0.244601</td>
      <td>0.206551</td>
      <td>0.191956</td>
      <td>-0.081857</td>
      <td>0.186556</td>
      <td>-0.284893</td>
      <td>0.041502</td>
      <td>-0.086824</td>
      <td>-0.062837</td>
      <td>-0.112964</td>
      <td>...</td>
      <td>-0.044429</td>
      <td>0.044429</td>
      <td>-1.000000</td>
      <td>1.000000</td>
      <td>-0.063407</td>
      <td>0.063407</td>
      <td>0.103002</td>
      <td>-0.103002</td>
      <td>0.096707</td>
      <td>-0.096707</td>
    </tr>
    <tr>
      <th>internet_no</th>
      <td>0.033229</td>
      <td>-0.249728</td>
      <td>-0.170012</td>
      <td>0.169485</td>
      <td>-0.049695</td>
      <td>0.074263</td>
      <td>-0.065972</td>
      <td>-0.061016</td>
      <td>-0.083766</td>
      <td>-0.039511</td>
      <td>...</td>
      <td>-0.002605</td>
      <td>0.002605</td>
      <td>0.063407</td>
      <td>-0.063407</td>
      <td>1.000000</td>
      <td>-1.000000</td>
      <td>0.049882</td>
      <td>-0.049882</td>
      <td>-0.078377</td>
      <td>0.078377</td>
    </tr>
    <tr>
      <th>internet_yes</th>
      <td>-0.033229</td>
      <td>0.249728</td>
      <td>0.170012</td>
      <td>-0.169485</td>
      <td>0.049695</td>
      <td>-0.074263</td>
      <td>0.065972</td>
      <td>0.061016</td>
      <td>0.083766</td>
      <td>0.039511</td>
      <td>...</td>
      <td>0.002605</td>
      <td>-0.002605</td>
      <td>-0.063407</td>
      <td>0.063407</td>
      <td>-1.000000</td>
      <td>1.000000</td>
      <td>-0.049882</td>
      <td>0.049882</td>
      <td>0.078377</td>
      <td>-0.078377</td>
    </tr>
    <tr>
      <th>romantic_no</th>
      <td>-0.173800</td>
      <td>0.008685</td>
      <td>0.039906</td>
      <td>-0.013603</td>
      <td>-0.038435</td>
      <td>-0.076042</td>
      <td>0.051891</td>
      <td>-0.012372</td>
      <td>-0.003606</td>
      <td>-0.045311</td>
      <td>...</td>
      <td>-0.003646</td>
      <td>0.003646</td>
      <td>-0.103002</td>
      <td>0.103002</td>
      <td>0.049882</td>
      <td>-0.049882</td>
      <td>1.000000</td>
      <td>-1.000000</td>
      <td>0.034534</td>
      <td>-0.034534</td>
    </tr>
    <tr>
      <th>romantic_yes</th>
      <td>0.173800</td>
      <td>-0.008685</td>
      <td>-0.039906</td>
      <td>0.013603</td>
      <td>0.038435</td>
      <td>0.076042</td>
      <td>-0.051891</td>
      <td>0.012372</td>
      <td>0.003606</td>
      <td>0.045311</td>
      <td>...</td>
      <td>0.003646</td>
      <td>-0.003646</td>
      <td>0.103002</td>
      <td>-0.103002</td>
      <td>-0.049882</td>
      <td>0.049882</td>
      <td>-1.000000</td>
      <td>1.000000</td>
      <td>-0.034534</td>
      <td>0.034534</td>
    </tr>
    <tr>
      <th>class_math</th>
      <td>-0.018790</td>
      <td>0.101246</td>
      <td>0.094795</td>
      <td>-0.079881</td>
      <td>0.060934</td>
      <td>0.083043</td>
      <td>0.007091</td>
      <td>0.025949</td>
      <td>-0.032011</td>
      <td>-0.011335</td>
      <td>...</td>
      <td>0.009498</td>
      <td>-0.009498</td>
      <td>-0.096707</td>
      <td>0.096707</td>
      <td>-0.078377</td>
      <td>0.078377</td>
      <td>0.034534</td>
      <td>-0.034534</td>
      <td>1.000000</td>
      <td>-1.000000</td>
    </tr>
    <tr>
      <th>class_por</th>
      <td>0.018790</td>
      <td>-0.101246</td>
      <td>-0.094795</td>
      <td>0.079881</td>
      <td>-0.060934</td>
      <td>-0.083043</td>
      <td>-0.007091</td>
      <td>-0.025949</td>
      <td>0.032011</td>
      <td>0.011335</td>
      <td>...</td>
      <td>-0.009498</td>
      <td>0.009498</td>
      <td>0.096707</td>
      <td>-0.096707</td>
      <td>0.078377</td>
      <td>-0.078377</td>
      <td>-0.034534</td>
      <td>0.034534</td>
      <td>-1.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>61 rows × 61 columns</p>
</div>



### 알콜 정도
 - 주중 알콜 중독정도 (Dalc)
 - 주말 알콜 중독정도 (Walc)


```python
pd.DataFrame({'Walc':corr['Walc'], 'Dalc':corr['Dalc']}).T 
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>Medu</th>
      <th>Fedu</th>
      <th>traveltime</th>
      <th>studytime</th>
      <th>failures</th>
      <th>famrel</th>
      <th>freetime</th>
      <th>goout</th>
      <th>Dalc</th>
      <th>...</th>
      <th>nursery_no</th>
      <th>nursery_yes</th>
      <th>higher_no</th>
      <th>higher_yes</th>
      <th>internet_no</th>
      <th>internet_yes</th>
      <th>romantic_no</th>
      <th>romantic_yes</th>
      <th>class_math</th>
      <th>class_por</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Dalc</th>
      <td>0.133453</td>
      <td>0.001515</td>
      <td>-0.000165</td>
      <td>0.109423</td>
      <td>-0.159665</td>
      <td>0.116336</td>
      <td>-0.076483</td>
      <td>0.144979</td>
      <td>0.253135</td>
      <td>1.000000</td>
      <td>...</td>
      <td>0.080647</td>
      <td>-0.080647</td>
      <td>0.112964</td>
      <td>-0.112964</td>
      <td>-0.039511</td>
      <td>0.039511</td>
      <td>-0.045311</td>
      <td>0.045311</td>
      <td>-0.011335</td>
      <td>0.011335</td>
    </tr>
    <tr>
      <th>Walc</th>
      <td>0.098291</td>
      <td>-0.029331</td>
      <td>0.019524</td>
      <td>0.084292</td>
      <td>-0.229073</td>
      <td>0.107432</td>
      <td>-0.100663</td>
      <td>0.130377</td>
      <td>0.399794</td>
      <td>0.627814</td>
      <td>...</td>
      <td>0.084874</td>
      <td>-0.084874</td>
      <td>0.087271</td>
      <td>-0.087271</td>
      <td>-0.043615</td>
      <td>0.043615</td>
      <td>0.016426</td>
      <td>-0.016426</td>
      <td>0.004043</td>
      <td>-0.004043</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 61 columns</p>
</div>




```python
Rel_Dalc = corr['Dalc']
Rel_Walc = corr['Walc']
```

 - 상관계수가 0.1 이상인 변수만 추출 => 절대값을 하는 이유는 특정 변수가 높을 수록 술을 적게 먹는 변수도 찾기 위해서 


```python
Rel_Dalc[abs(Rel_Dalc)>0.1]
```




    age                  0.133453
    traveltime           0.109423
    studytime           -0.159665
    failures             0.116336
    freetime             0.144979
    goout                0.253135
    Dalc                 1.000000
    Walc                 0.627814
    absences             0.132867
    G1                  -0.150943
    G2                  -0.131576
    G3                  -0.129642
    sex_F               -0.275928
    sex_M                0.275928
    reason_other         0.133297
    reason_reputation   -0.102682
    higher_no            0.112964
    higher_yes          -0.112964
    Name: Dalc, dtype: float64




```python
Rel_Walc[abs(Rel_Walc)>0.1]
```




    studytime   -0.229073
    failures     0.107432
    famrel      -0.100663
    freetime     0.130377
    goout        0.399794
    Dalc         0.627814
    Walc         1.000000
    health       0.106669
    absences     0.139703
    G1          -0.142401
    G2          -0.128114
    G3          -0.115740
    sex_F       -0.302623
    sex_M        0.302623
    Name: Walc, dtype: float64



 - Index명 추출.


```python
Rel_Col_Dal = Rel_Dalc[abs(Rel_Dalc)>0.1].index.tolist()
Rel_Col_Wal = Rel_Walc[abs(Rel_Walc)>0.1].index.tolist()
```


```python
Dal_df = X[Rel_Col_Dal]
Wal_df = X[Rel_Col_Wal]
```


```python
Dal_df.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>traveltime</th>
      <th>studytime</th>
      <th>failures</th>
      <th>freetime</th>
      <th>goout</th>
      <th>Dalc</th>
      <th>Walc</th>
      <th>absences</th>
      <th>G1</th>
      <th>G2</th>
      <th>G3</th>
      <th>sex_F</th>
      <th>sex_M</th>
      <th>reason_other</th>
      <th>reason_reputation</th>
      <th>higher_no</th>
      <th>higher_yes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>18</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>6</td>
      <td>5</td>
      <td>6</td>
      <td>6</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>17</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>4</td>
      <td>5</td>
      <td>5</td>
      <td>6</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>15</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>10</td>
      <td>7</td>
      <td>8</td>
      <td>10</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>15</td>
      <td>1</td>
      <td>3</td>
      <td>0</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>15</td>
      <td>14</td>
      <td>15</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>16</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>4</td>
      <td>6</td>
      <td>10</td>
      <td>10</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
Wal_df.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>studytime</th>
      <th>failures</th>
      <th>famrel</th>
      <th>freetime</th>
      <th>goout</th>
      <th>Dalc</th>
      <th>Walc</th>
      <th>health</th>
      <th>absences</th>
      <th>G1</th>
      <th>G2</th>
      <th>G3</th>
      <th>sex_F</th>
      <th>sex_M</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>0</td>
      <td>4</td>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>6</td>
      <td>5</td>
      <td>6</td>
      <td>6</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0</td>
      <td>5</td>
      <td>3</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>4</td>
      <td>5</td>
      <td>5</td>
      <td>6</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>3</td>
      <td>4</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>3</td>
      <td>10</td>
      <td>7</td>
      <td>8</td>
      <td>10</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>0</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>2</td>
      <td>15</td>
      <td>14</td>
      <td>15</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>0</td>
      <td>4</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>5</td>
      <td>4</td>
      <td>6</td>
      <td>10</td>
      <td>10</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
Dal_corr = Dal_df.corr()
Wal_corr = Wal_df.corr()
```

### 결론 
 - 남자학생의 경우가 여성의 학생보다 알콜 중독 현상이 높다.
 - 당연한 얘기로 밖에 친구와 많이 놀러 가는 학생이 알콜에 노출될 확률이 높으므로 더 많은 섭취 현상을 보였다. 
 - 자유 시간이 많은 학생이 위와 같은 원인으로 더 많은 노출이 되었다. 
 - 주중 / 주말 알콜 섭취 비율은 당연히 상관관계가 제일 높았다. 
 - 결석을 많이 하는 학생 또한 약간의 상관 관계를 가지고 있으나 확정적이지는 않다. 


```python
fig, ax = plt.subplots(figsize=(10,10)) 
sns.heatmap(Dal_corr, 
            xticklabels=Dal_corr.columns.values,
            yticklabels=Dal_corr.columns.values,
           annot=True, linewidths=.5, ax=ax)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x19b17c00dd8>




![png](/src/0609/ALCO/output_39_1.png)



```python
fig, ax = plt.subplots(figsize=(10,10)) 
sns.heatmap(Wal_corr, 
            xticklabels=Wal_corr.columns.values,
            yticklabels=Wal_corr.columns.values,
            annot=True, linewidths=.5, ax=ax)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x19b1779d8d0>




![png](/src/0609/ALCO/output_40_1.png)



```python
sns.boxplot(x='goout',y='Walc',data=df)            
```




    <matplotlib.axes._subplots.AxesSubplot at 0x19b185dddd8>




![png](/src/0609/ALCO/output_41_1.png)



```python
sns.boxplot(x='goout',y='Dalc',data=df) 
```




    <matplotlib.axes._subplots.AxesSubplot at 0x19b186df630>




![png](/src/0609/ALCO/output_42_1.png)


 - 여성의 알콜 중독 비율이 남자학생보다 훨씬 낮다. 


```python
sns.factorplot('Walc',kind='count',hue='sex',data=df)   
```




    <seaborn.axisgrid.FacetGrid at 0x19b187dc320>




![png](/src/0609/ALCO/output_44_1.png)


# Machine Learning 예측 


```python
X[['Walc','Dalc']].head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Walc</th>
      <th>Dalc</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
X['Alcohol'] = X['Walc'] + X['Dalc']
```


```python
X['Alcohol'].head()
```




    0    2
    1    2
    2    5
    3    2
    4    3
    Name: Alcohol, dtype: int64




```python
ml_df = X.copy()
```


```python
ml_df['Alcohol'].value_counts()
```




    2     391
    3     182
    4     159
    5     118
    6      85
    7      49
    8      26
    10     24
    9      10
    Name: Alcohol, dtype: int64




```python
from sklearn.utils import shuffle
```


```python
ml_df = shuffle(ml_df)
```


```python
ml_df = ml_df.reset_index()
```


```python
del ml_df['index']
```


```python
ml_df_columns = ml_df.columns.difference(['Walc','Dalc','Alcohol'])
```


```python
ml_df_columns
```




    Index(['Fedu', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services',
           'Fjob_teacher', 'G1', 'G2', 'G3', 'Medu', 'Mjob_at_home', 'Mjob_health',
           'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Pstatus_A', 'Pstatus_T',
           'absences', 'activities_no', 'activities_yes', 'address_R', 'address_U',
           'age', 'class_math', 'class_por', 'failures', 'famrel', 'famsize_GT3',
           'famsize_LE3', 'famsup_no', 'famsup_yes', 'freetime', 'goout',
           'guardian_father', 'guardian_mother', 'guardian_other', 'health',
           'higher_no', 'higher_yes', 'internet_no', 'internet_yes', 'nursery_no',
           'nursery_yes', 'paid_no', 'paid_yes', 'reason_course', 'reason_home',
           'reason_other', 'reason_reputation', 'romantic_no', 'romantic_yes',
           'school_GP', 'school_MS', 'schoolsup_no', 'schoolsup_yes', 'sex_F',
           'sex_M', 'studytime', 'traveltime'],
          dtype='object')




```python
X = ml_df[ml_df_columns]
```


```python
y = ml_df['Alcohol']
```


```python
print(ml_df.columns)
ml_df.head()
```

    Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',
           'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2',
           'G3', 'school_GP', 'school_MS', 'sex_F', 'sex_M', 'address_R',
           'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T',
           'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services',
           'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other',
           'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home',
           'reason_other', 'reason_reputation', 'guardian_father',
           'guardian_mother', 'guardian_other', 'schoolsup_no', 'schoolsup_yes',
           'famsup_no', 'famsup_yes', 'paid_no', 'paid_yes', 'activities_no',
           'activities_yes', 'nursery_no', 'nursery_yes', 'higher_no',
           'higher_yes', 'internet_no', 'internet_yes', 'romantic_no',
           'romantic_yes', 'class_math', 'class_por', 'Alcohol'],
          dtype='object')
    




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>Medu</th>
      <th>Fedu</th>
      <th>traveltime</th>
      <th>studytime</th>
      <th>failures</th>
      <th>famrel</th>
      <th>freetime</th>
      <th>goout</th>
      <th>Dalc</th>
      <th>...</th>
      <th>nursery_yes</th>
      <th>higher_no</th>
      <th>higher_yes</th>
      <th>internet_no</th>
      <th>internet_yes</th>
      <th>romantic_no</th>
      <th>romantic_yes</th>
      <th>class_math</th>
      <th>class_por</th>
      <th>Alcohol</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>16</td>
      <td>4</td>
      <td>4</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>4</td>
      <td>4</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>16</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>4</td>
      <td>4</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>16</td>
      <td>4</td>
      <td>4</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>4</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>3</th>
      <td>17</td>
      <td>4</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>5</td>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>19</td>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>4</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 62 columns</p>
</div>




```python
y[:5]
```




    0    2
    1    2
    2    6
    3    3
    4    2
    Name: Alcohol, dtype: int64



## 데이터 분할 


```python
from sklearn.model_selection import train_test_split
```


```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)
```


```python
from sklearn.linear_model import LinearRegression
```


```python
lm = LinearRegression()
```


```python
X_train.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fedu</th>
      <th>Fjob_at_home</th>
      <th>Fjob_health</th>
      <th>Fjob_other</th>
      <th>Fjob_services</th>
      <th>Fjob_teacher</th>
      <th>G1</th>
      <th>G2</th>
      <th>G3</th>
      <th>Medu</th>
      <th>...</th>
      <th>romantic_no</th>
      <th>romantic_yes</th>
      <th>school_GP</th>
      <th>school_MS</th>
      <th>schoolsup_no</th>
      <th>schoolsup_yes</th>
      <th>sex_F</th>
      <th>sex_M</th>
      <th>studytime</th>
      <th>traveltime</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>830</th>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>14</td>
      <td>14</td>
      <td>15</td>
      <td>4</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>172</th>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>15</td>
      <td>14</td>
      <td>15</td>
      <td>3</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1005</th>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>12</td>
      <td>11</td>
      <td>12</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1013</th>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>11</td>
      <td>10</td>
      <td>10</td>
      <td>2</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>397</th>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>10</td>
      <td>10</td>
      <td>11</td>
      <td>3</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 59 columns</p>
</div>




```python
lm.fit(X_train, y_train)
```




    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)




```python
lm.intercept_ #  절편
```




    -552496061212.00085




```python
lm.coef_ #기울기
```




    array([  1.10681983e-01,   7.62085702e+11,   7.62085702e+11,
             7.62085702e+11,   7.62085702e+11,   7.62085702e+11,
            -1.16823836e-01,   6.91050842e-02,  -3.45437923e-03,
            -1.71508789e-02,  -1.42382326e+10,  -1.42382326e+10,
            -1.42382326e+10,  -1.42382326e+10,  -1.42382326e+10,
            -2.79352456e+09,  -2.79352456e+09,   4.22363281e-02,
            -1.04961259e+10,  -1.04961259e+10,   2.35242131e+09,
             2.35242131e+09,   1.11968994e-01,  -4.36248354e+09,
            -4.36248354e+09,   7.52563477e-02,  -3.29772949e-01,
            -1.10872374e+08,  -1.10872374e+08,   1.12212080e+10,
             1.12212080e+10,   8.78906250e-03,   5.69213867e-01,
            -7.05294877e+09,  -7.05294877e+09,  -7.05294877e+09,
             1.04492188e-01,   8.30723019e+09,   8.30723019e+09,
             5.57260644e+09,   5.57260644e+09,  -6.15471185e+08,
            -6.15471186e+08,   4.73224834e+09,   4.73224834e+09,
            -8.98184669e+10,  -8.98184669e+10,  -8.98184669e+10,
            -8.98184669e+10,   4.35991140e+10,   4.35991140e+10,
            -1.55858529e+11,  -1.55858529e+11,   1.15810618e+10,
             1.15810618e+10,  -1.16088761e+10,  -1.16088761e+10,
            -1.85943604e-01,   1.70471191e-01])




```python
from sklearn.metrics import mean_squared_error
```


```python
mean_squared_error(y_train,lm.predict(X_train))
```




    2.659151246163943




```python
mean_squared_error(y_test,lm.predict(X_test))
```




    2.4619246322163351




```python
compare_alcohol = pd.DataFrame({'prediction':lm.predict(X_test),'real_value':y_test})
```


```python
compare_alcohol['prediction'] = round(compare_alcohol['prediction'])
```


```python
compare_alcohol['diff'] = compare_alcohol['prediction'] - compare_alcohol['real_value']
```


```python
compare_alcohol['diff'].value_counts()
```




     1.0    83
     0.0    72
    -1.0    54
     2.0    49
    -2.0    30
    -3.0     8
     3.0     8
     4.0     3
    -5.0     3
    -4.0     3
     6.0     1
    Name: diff, dtype: int64



## Classification으로 풀기 


```python
from sklearn.ensemble import GradientBoostingClassifier
```


```python
from sklearn import metrics
```


```python
gb = GradientBoostingClassifier(n_estimators=3000)
```


```python
gb.fit(X_train,y_train)
```




    GradientBoostingClassifier(criterion='friedman_mse', init=None,
                  learning_rate=0.1, loss='deviance', max_depth=3,
                  max_features=None, max_leaf_nodes=None,
                  min_impurity_split=1e-07, min_samples_leaf=1,
                  min_samples_split=2, min_weight_fraction_leaf=0.0,
                  n_estimators=3000, presort='auto', random_state=None,
                  subsample=1.0, verbose=0, warm_start=False)




```python
def getResult(y_test,y_pred):
    print(metrics.confusion_matrix(y_test, y_pred))
    print('accurracy:', metrics.accuracy_score(y_test, y_pred))
```


```python
gb.predict(X_test)
```




    array([ 3,  3,  2,  2,  3,  3,  2,  5,  3,  4,  2,  4,  3,  2,  7,  2,  5,
            2,  5,  2,  2,  2,  4,  2,  2,  6,  2,  5,  2,  6,  5,  2,  2,  7,
            5,  2,  2,  2,  6,  2,  3,  4,  2,  5,  2,  5,  2,  3,  6, 10,  4,
            3,  4, 10,  2,  2,  2,  4,  4,  2,  2,  2,  2,  2,  2,  3,  2,  4,
            4,  4,  3,  2,  3,  3,  2,  2,  2,  2,  6,  2,  5,  2,  5,  3,  3,
            6,  2,  2,  3,  7,  6,  5,  5,  4,  2,  2,  3,  3,  2,  4,  6,  4,
            4,  5,  2,  5,  3,  2,  3,  2,  2,  3,  3,  4,  6,  5,  5,  6,  2,
            2,  8,  2,  6,  5,  2,  3,  2,  6,  2,  5,  2,  2,  3,  6,  4,  3,
            2,  3,  3,  2,  2,  4,  2,  2,  4,  2,  4,  5,  3,  2,  2,  2,  3,
            2,  4,  8,  2,  2,  2,  5,  2,  5,  2,  2,  2,  2,  3,  6,  3,  7,
            6,  2,  2,  3,  2,  8,  4,  2,  2,  2,  4,  2,  6,  6,  2,  2,  2,
            2,  2,  2,  2,  2,  5,  2,  3,  6,  2,  6,  2,  3,  2,  2,  2,  2,
            4,  4,  3,  2,  4,  3,  2,  7,  4,  5,  6,  2,  2,  4,  3,  4,  6,
            3,  2,  7,  3,  4,  5,  2,  2,  3,  2,  6,  4,  3,  6,  3,  2,  2,
            3,  4,  2,  2,  2,  5,  7,  7,  4,  5,  2,  4,  2,  2,  2,  3,  4,
            3,  2,  3,  2,  3,  2,  4,  2,  2,  6,  2,  5,  7,  2,  3,  2,  2,
            4,  5,  2,  2,  5,  4,  3,  3,  2,  2,  3,  4,  7,  2,  3,  2,  3,
            2,  2,  2,  2,  3,  4,  2,  4,  3,  3,  4,  2,  3,  5,  2,  3,  2,
            2,  2,  2,  4,  2,  2,  2,  7], dtype=int64)




```python
getResult(gb.predict(X_test),y_test)
```

    [[86 22 14 14  5  2  0  0  0]
     [14 18 12  9  2  3  0  0  0]
     [ 6  7 25  2  2  0  0  0  1]
     [ 2  3  1 16  2  2  2  0  2]
     [ 3  2  0  2  9  6  1  1  0]
     [ 3  2  0  0  1  5  0  0  0]
     [ 1  0  0  0  0  1  1  0  0]
     [ 0  0  0  0  0  0  0  0  0]
     [ 0  0  1  0  0  0  0  0  1]]
    accurracy: 0.512738853503
    

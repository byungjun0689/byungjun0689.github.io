---
layout: post
title: "MNIST (Classification of hand writing using tensorflow(keras))"
date: 2017-06-10 11:10:26
img: 'MNIST.png'
description: 'MNIST (Classification of hand writing using tensorflow(keras))'
main-class: 'keras'
tags:
- python
- classification
- mnist 
- keras 
---

- This is basic Neural Network Sample
- Classification of Hand Writing with DeepLearning (Keras)

# DeepLearning (MINST)
 - ê¸°ì¡´ tensorflow ì´ ê¹”ë ¤ì ¸ìˆë‹¤ë©´ 1.0ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ 
 - pip uninstall tensorflow -> pip install tensorflow


```python
import keras
```

    Using TensorFlow backend.
    


```python
from keras.datasets import mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
```

    Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz
    


```python
n_train, width, height = x_train.shape
```


```python
n_train
```




    60000



 - 60000ê°œì˜ ë°ì´í„° 28x28 pictures


```python
width
```




    28




```python
height
```




    28




```python
n_test, _, _ = x_test.shape
```


```python
n_test
```




    10000




```python
%matplotlib inline
```

## ë°ì´í„° ë³´ê¸° 


```python
import matplotlib.pyplot as plt
```


```python
plt.imshow(x_train[4,:], cmap='gray')
```




    <matplotlib.image.AxesImage at 0x289fdaec9b0>




![png](/src/0610/MNIST/output_13_1.png)



```python
y_train[4,]
```




    9



## ë°ì´í„° ì „ì²˜ë¦¬ 
### ì…ë ¥ 
 - 28x28ì˜ ë°ì´í„°ê°€ 60000ê°œê°€ ìˆë‹¤. 3ì°¨ì› 
 - ì­‰ 60000 x 728í˜•íƒœë¡œ ë³€í™˜ ì‹œí‚¤ë ¤ê³ í•˜ëŠ” ê²ƒì´ë‹¤. ì ì„ ìˆœì„œëŒ€ë¡œ ë³€í™˜ 


```python
input_train = x_train.reshape(n_train, width*height) 
```


```python
input_train.shape
```




    (60000, 784)




```python
input_train.astype('float32')
```




    array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],
           [ 0.,  0.,  0., ...,  0.,  0.,  0.],
           [ 0.,  0.,  0., ...,  0.,  0.,  0.],
           ..., 
           [ 0.,  0.,  0., ...,  0.,  0.,  0.],
           [ 0.,  0.,  0., ...,  0.,  0.,  0.],
           [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)




```python
input_train.max()
```




    255




```python
input_train.min()
```




    0




```python
input_train = input_train / 255.0 # 0~1ë¡œ ë°ì´í„°ë¡œ sacle
```


```python
input_train.max()
```




    1.0



 - í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬ 


```python
input_test = x_test.reshape(n_test, width*height)
input_test.astype('float32')
input_test = input_test / 255.0
```

### ì¶œë ¥ 
 - 0ì´ë¼ëŠ” ë¬¸ìê°€ ìˆë‹¤. ì™¼ìª½ ë°˜ì„ ì§€ìš°ë©´ 1ì´ëœë‹¤ í•˜ì§€ë§Œ ë˜ ë°˜ì„ ì§€ìš´ë‹¤ê³ í•´ì„œ 2ê°€ ë˜ì§€ëŠ” ì•ŠëŠ”ë‹¤. 
 - ìˆ«ìëŠ” ë²”ì£¼í˜• ë°ì´í„°ì´ë‹¤. (ê·¸ë¦¼ì€)


```python
output_train = keras.utils.to_categorical(y_train,10) # 0~9ê¹Œì§€ë¥¼ ì¹´í…Œê³ ë¦¬ë¡œ ë³€í™˜ 
```


```python
output_train # one-hot encoding 
```




    array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],
           [ 1.,  0.,  0., ...,  0.,  0.,  0.],
           [ 0.,  0.,  0., ...,  0.,  0.,  0.],
           ..., 
           [ 0.,  0.,  0., ...,  0.,  0.,  0.],
           [ 0.,  0.,  0., ...,  0.,  0.,  0.],
           [ 0.,  0.,  0., ...,  0.,  1.,  0.]])




```python
output_test = keras.utils.to_categorical(y_test, 10)
```

### ê°„ë‹¨í•œ ëª¨ë¸ 


```python
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import RMSprop
```


```python
model = Sequential()
model.add(Dense(392, activation='tanh', input_shape=(784,)))
model.add(Dense(10, activation='softmax')) # slideë³´ê¸° 
```


```python
model.summary() # dense_1 ì—ëŠ” 762 * 392 + 392 biasê°€ ìˆë‹¤. ë¼ëŠ” param
```

    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    dense_1 (Dense)              (None, 392)               307720    
    _________________________________________________________________
    dense_2 (Dense)              (None, 10)                3930      
    =================================================================
    Total params: 311,650.0
    Trainable params: 311,650
    Non-trainable params: 0.0
    _________________________________________________________________
    

 - loss : ìš°ë¦¬ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ë¶€ì •í™•í•˜ëƒ 
  - mean_squared_error : MSE  âˆ’1/ğ‘ âˆ‘(ğ‘¦âˆ’ğ‘¦Â Ì‚ )^2 
  - cross entropy : ë‚´ê°€ ë­”ê°€ë¥¼ ë§ì¶œë•Œ ë†’ì€ í™•ë¥ ë¡œ ë§ì¶˜ê±°ë¥¼ ì¢‹ì•„í•´, ë‚®ì€ í™•ë¥ ë¡œ ë§ì¶˜ ê²ƒì€ lossê°€ ì»¤ì§„ë‹¤. ë°°íŒ…ì„ í¬ê²Œ í–ˆëŠ”ë° ëª»ë§ì¶”ë©´ loss ë˜í•œ ì»¤ì§„ë‹¤. 


```python
model.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(),
              metrics=['accuracy'])
```

### íŠ¸ë ˆì´ë‹ 


```python
batch_size = 128
epochs = 1
```


```python
history = model.fit(input_train, output_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1,
                    validation_data=(input_test, output_test))
```

    Train on 60000 samples, validate on 10000 samples
    Epoch 1/1
    60000/60000 [==============================] - 12s - loss: 0.1795 - acc: 0.9496 - val_loss: 0.2409 - val_acc: 0.9372
    


```python
history.history
```




    {'acc': [0.94961666666666666],
     'loss': [0.1795018165588379],
     'val_acc': [0.93720000000000003],
     'val_loss': [0.24085259833335876]}



### í‰ê°€ 


```python
score = model.evaluate(input_test, output_test, verbose=0)
```


```python
score
```




    [0.24085259948968887, 0.93720000000000003]


